{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import torch\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from utils import utils\n",
    "from dataset.dataset import ASLDataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import utils\n",
    "from torchvision.transforms import v2\n",
    "import torch \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibmelab/anaconda3/envs/2scnn/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Grayscale(num_output_channels=3),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5])  # Gray normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataLoader's with batch size 32 and 48 workers.\n",
      "train dataset size :72471 images \n",
      "test dataset size :14471 images \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and transform data\n",
    "\n",
    "train_dir = \"archive/asl_alphabet_train/asl_alphabet_train\"\n",
    "train_data_simple = ASLDataset(data_path=train_dir,range_index = [1,2500], transform=transform)\n",
    "test_data_simple = ASLDataset(data_path=train_dir,range_index = [2501,3000], transform=transform)\n",
    "\n",
    "# 2. Turn data into DataLoaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup batch size and number of workers \n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "print(f\"Creating DataLoader's with batch size {BATCH_SIZE} and {NUM_WORKERS} workers.\")\n",
    "\n",
    "# Create DataLoader's\n",
    "train_dataloader_simple = DataLoader(train_data_simple, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(test_data_simple, \n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    shuffle=False, \n",
    "                                    num_workers=NUM_WORKERS)\n",
    "print(f'train dataset size :{len(train_data_simple)} images ')\n",
    "print(f'test dataset size :{len(test_data_simple)} images ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X,XN, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X,XN, y = X.to(device),XN.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X,XN,y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X,XN,y = X.to(device),XN.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num must be an integer with 1 <= num <= 20, not 30",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Display the image pairs\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mdisplay_image_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 27\u001b[0m, in \u001b[0;36mdisplay_image_pairs\u001b[0;34m(dataloader, num_pairs)\u001b[0m\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_idx\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(transforms\u001b[38;5;241m.\u001b[39mToPILImage()(img2\u001b[38;5;241m.\u001b[39msqueeze()))\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_idx\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/2scnn/lib/python3.11/site-packages/matplotlib/pyplot.py:1425\u001b[0m, in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1422\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# First, search for an existing subplot with a matching spec.\u001b[39;00m\n\u001b[0;32m-> 1425\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mSubplotSpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_subplot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m fig\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;66;03m# If we found an Axes at the position, we can re-use it if the user passed no\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;66;03m# kwargs or if the axes class and kwargs are identical.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (ax\u001b[38;5;241m.\u001b[39mget_subplotspec() \u001b[38;5;241m==\u001b[39m key\n\u001b[1;32m   1431\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (kwargs \u001b[38;5;241m==\u001b[39m {}\n\u001b[1;32m   1432\u001b[0m              \u001b[38;5;129;01mor\u001b[39;00m (ax\u001b[38;5;241m.\u001b[39m_projection_init\n\u001b[1;32m   1433\u001b[0m                  \u001b[38;5;241m==\u001b[39m fig\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)))):\n",
      "File \u001b[0;32m~/anaconda3/envs/2scnn/lib/python3.11/site-packages/matplotlib/gridspec.py:599\u001b[0m, in \u001b[0;36mSubplotSpec._from_subplot_args\u001b[0;34m(figure, args)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(num, Integral) \u001b[38;5;129;01mor\u001b[39;00m num \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m num \u001b[38;5;241m>\u001b[39m rows\u001b[38;5;241m*\u001b[39mcols:\n\u001b[0;32m--> 599\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    600\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum must be an integer with 1 <= num <= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrows\u001b[38;5;241m*\u001b[39mcols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m         )\n\u001b[1;32m    603\u001b[0m     i \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m=\u001b[39m num\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:j]\n",
      "\u001b[0;31mValueError\u001b[0m: num must be an integer with 1 <= num <= 20, not 30"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define your data path and range index\n",
    "data_path = \"archive/asl_alphabet_train/asl_alphabet_train\"\n",
    "range_index = (1000,1019)  # Specify the range for the first 20 images\n",
    "\n",
    "# Create an instance of your ASLDataset\n",
    "dataset = ASLDataset(data_path, range_index, transform=transforms.ToTensor())\n",
    "\n",
    "# Create a DataLoader to iterate through the dataset\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Function to display image pairs consecutively\n",
    "def display_image_pairs(dataloader, num_pairs=20):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "    for i, (img1, img2, class_idx) in enumerate(dataloader):\n",
    "        if class_idx == 1:\n",
    "            plt.subplot(2, 10, i+1)\n",
    "            plt.imshow(transforms.ToPILImage()(img1.squeeze()))\n",
    "            plt.title(f'Class: {class_idx.item()}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(2, 10, i+11)\n",
    "            plt.imshow(transforms.ToPILImage()(img2.squeeze()))\n",
    "            plt.title(f'Class: {class_idx.item()}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            if i == num_pairs - 1:\n",
    "                break\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Display the image pairs\n",
    "display_image_pairs(dataloader, num_pairs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
